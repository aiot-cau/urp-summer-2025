# AI ì¶”ì²œ ë…¼ë¬¸ ëª©ë¡
- **ì¤‘ìš”ë„**: â—â—‹â—‹ (ì°¸ê³ ), â—â—â—‹ (ê¶Œì¥), â—â—â— (í•„ìˆ˜)  
- **ë‚œì´ë„**: â—â—‹â—‹ (ì…ë¬¸), â—â—â—‹ (ì¤‘ê¸‰), â—â—â— (ê³ ê¸‰)  

## ğŸ“· ì´ë¯¸ì§€ ë¶„ì•¼

### 1. [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) (ResNet)
- **ì €ì**: K. He, X. Zhang, S. Ren, J. Sun
- **í•™íšŒ/ì €ë„**: CVPR 2016
- **ì¤‘ìš”ë„**: â—â—â— | **ë‚œì´ë„**: â—â—â—‹
- **ìš”ì•½**: Skip connectionì„ ë„ì…í•˜ì—¬ ë§¤ìš° ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“  íšê¸°ì ì¸ êµ¬ì¡°ë¡œ, ì´í›„ì˜ ë§ì€ CNN ëª¨ë¸ì˜ ê¸°ë°˜ì´ ë¨.

### 2. [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861) (MobileNets)
- **ì €ì**: A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko
- **í•™íšŒ/ì €ë„**: arXiv 2017
- **ì¤‘ìš”ë„**: â—â—â—‹ | **ë‚œì´ë„**: â—â—‹â—‹
- **ìš”ì•½**: Depthwise Separable Convolutionì„ ì´ìš©í•´ ì—°ì‚°ëŸ‰ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì¸ ê²½ëŸ‰í™” CNNìœ¼ë¡œ, ëª¨ë°”ì¼ ë° ì„ë² ë””ë“œ ë¹„ì „ í™˜ê²½ì— ìµœì í™”ë¨.

### 3. [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) (ViT)
- **ì €ì**: A. Dosovitskiy et al.
- **í•™íšŒ/ì €ë„**: ICLR 2021
- **ì¤‘ìš”ë„**: â—â—â— | **ë‚œì´ë„**: â—â—â—
- **ìš”ì•½**: ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œë¥¼ Transformer êµ¬ì¡°ë¡œ í’€ì–´ë‚¸ ìµœì´ˆì˜ ì—°êµ¬ë¡œ, CNN ì¤‘ì‹¬ì˜ ì»´í“¨í„°ë¹„ì „ íŒ¨ëŸ¬ë‹¤ì„ì„ Transformerë¡œ í™•ì¥í•¨.

## ğŸ“ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼

### 1. [Attention is All You Need](https://arxiv.org/abs/1706.03762) (Transformer)
- **ì €ì**: A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit et al.
- **í•™íšŒ/ì €ë„**: NeurIPS 2017
- **ì¤‘ìš”ë„**: â—â—â— | **ë‚œì´ë„**: â—â—â—‹
- **ìš”ì•½**: Self-Attention ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•´ ìˆœì°¨ì ì¸ êµ¬ì¡° ì—†ì´ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ì—ˆìœ¼ë©°, ì´í›„ ëŒ€ë¶€ë¶„ì˜ NLP ëª¨ë¸ì˜ ê¸°ë°˜ì´ ë¨.

### 2. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) (BERT)
- **ì €ì**: J. Devlin, M. Chang, K. Lee, K. Toutanova
- **í•™íšŒ/ì €ë„**: NAACL 2019
- **ì¤‘ìš”ë„**: â—â—â— | **ë‚œì´ë„**: â—â—â—‹
- **ìš”ì•½**: ì–‘ë°©í–¥ Transformer êµ¬ì¡°ë¥¼ í™œìš©í•´ ë¬¸ë§¥ì„ ì •êµí•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ì œì•ˆí•˜ë©°, ë‹¤ì–‘í•œ NLP íƒœìŠ¤í¬ì—ì„œ SOTA ë‹¬ì„±.

## â³ ì‹œê³„ì—´ ë¶„ì•¼

### 1. [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477) (wav2vec 2.0)
- **ì €ì**: A. Baevski, H. Zhou, A. Mohamed, M. Auli
- **í•™íšŒ/ì €ë„**: NeurIPS 2020
- **ì¤‘ìš”ë„**: â—â—â— | **ë‚œì´ë„**: â—â—â—
- **ìš”ì•½**: ìŒì„± ë°ì´í„°ì—ì„œ ë¼ë²¨ ì—†ì´ë„ representationì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ self-supervised ë°©ì‹ì˜ ìŒì„± ì¸ì‹ ëª¨ë¸ì„ ì œì•ˆí•¨.

### 2. [A Decoder-Only Foundation Model for Time-Series Forecasting](https://arxiv.org/abs/2310.10688) (TimesFM)
- **ì €ì**: J. Wu, M. J. Zhang, Y. Chen, Q. Zhou, Y. Wu
- **í•™íšŒ/ì €ë„**: ICLR 2023
- **ì¤‘ìš”ë„**: â—â—â—‹ | **ë‚œì´ë„**: â—â—â—‹
- **ìš”ì•½**: ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ìœ„í•´ decoder-only êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ foundation modelì„ ì œì•ˆí•˜ë©°, ë‹¤ì–‘í•œ ì‹œê³„ì—´ ë°ì´í„°ì— ë²”ìš© ì ìš© ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤Œ.

## ğŸ§¬ ìƒì„±í˜• ëª¨ë¸ ë¶„ì•¼

### 1. [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (GAN)
- **ì €ì**: I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, et al.
- **í•™íšŒ/ì €ë„**: NeurIPS 2014
- **ì¤‘ìš”ë„**: â—â—â— | **ë‚œì´ë„**: â—â—â—
- **ìš”ì•½**: Generatorì™€ Discriminatorê°€ ê²½ìŸí•˜ëŠ” ì ëŒ€ì  í•™ìŠµ êµ¬ì¡°ë¡œ, ìƒì„± ëª¨ë¸ì˜ íŒ¨ëŸ¬ë‹¤ì„ì„ íšê¸°ì ìœ¼ë¡œ ì „í™˜ì‹œí‚¨ ê¸°ë…ë¹„ì  ë…¼ë¬¸.

### 2. [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937) (VQ-VAE)
- **ì €ì**: A. van den Oord, O. Vinyals, K. Kavukcuoglu
- **í•™íšŒ/ì €ë„**: NeurIPS 2017
- **ì¤‘ìš”ë„**: â—â—â—‹ | **ë‚œì´ë„**: â—â—â—‹
- **ìš”ì•½**: ë²¡í„° ì–‘ìí™”ë¥¼ í†µí•´ discrete latent spaceë¥¼ í˜•ì„±í•˜ê³ , ì•ˆì •ì ì¸ ìƒì„±ê³¼ ì••ì¶• í‘œí˜„ì„ ë™ì‹œì— ë‹¬ì„±í•œ ìƒì„± ëª¨ë¸.

### 3. [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) (DDPM)
- **ì €ì**: J. Ho, A. Jain, P. Abbeel
- **í•™íšŒ/ì €ë„**: NeurIPS 2020
- **ì¤‘ìš”ë„**: â—â—â— | **ë‚œì´ë„**: â—â—â—
- **ìš”ì•½**: ì ì§„ì ìœ¼ë¡œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” ê³¼ì •ì„ í†µí•´ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” diffusion ê¸°ë°˜ ëª¨ë¸ë¡œ, ìµœê·¼ ìƒì„± ëª¨ë¸ì˜ í•µì‹¬ íŠ¸ë Œë“œê°€ ë¨.

### 4. [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) (Stable Diffusion)
- **ì €ì**: R. Rombach, A. Blattmann, D. Lorenz, P. Esser, B. Ommer
- **í•™íšŒ/ì €ë„**: CVPR 2022
- **ì¤‘ìš”ë„**: â—â—â—‹ | **ë‚œì´ë„**: â—â—â—‹
- **ìš”ì•½**: ì ì¬ ê³µê°„ì—ì„œì˜ diffusionì„ í†µí•´ ê³„ì‚° íš¨ìœ¨ì„±ì„ ë†’ì´ë©´ì„œë„ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì´ ê°€ëŠ¥í•œ ëª¨ë¸ë¡œ ì‹¤ì „ í™œìš©ë„ê°€ ë†’ìŒ.

---

**ì°¸ê³ **: ì´ ëª©ë¡ì€ ê³„ì† ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. ì¶”ê°€í•˜ê³  ì‹¶ì€ ë…¼ë¬¸ì´ ìˆë‹¤ë©´ ì—°êµ¬ì‹¤ GitHub ì €ì¥ì†Œì— ê¸°ì—¬í•´ì£¼ì„¸ìš”.

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-05-30