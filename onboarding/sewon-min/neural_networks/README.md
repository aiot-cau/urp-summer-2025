## ì‹ ê²½ë§ ê°œìš”

ì‹ ê²½ë§ì€ `torch.nn` íŒ¨í‚¤ì§€ë¥¼ í†µí•´ ì •ì˜í•˜ë©°, `nn.Module`ì„ ìƒì†ë°›ì•„ ê³„ì¸µê³¼ forward ì—°ì‚°ì„ ì •ì˜í•œë‹¤. ë¯¸ë¶„ì€ `autograd`ê°€ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤.

---

### ì‹ ê²½ë§ í•™ìŠµ íë¦„

1. í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ì‹ ê²½ë§ì„ ì •ì˜í•œë‹¤.
2. ë°ì´í„°ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì…ë ¥í•œë‹¤.
3. ì…ë ¥ì„ ì‹ ê²½ë§ì— ì „ë‹¬í•˜ì—¬ ì¶œë ¥ì„ ì–»ëŠ”ë‹¤.
4. ì¶œë ¥ê³¼ ì •ë‹µì„ ë¹„êµí•˜ì—¬ ì†ì‹¤(loss)ì„ ê³„ì‚°í•œë‹¤.
5. ì†ì‹¤ì— ëŒ€í•´ ì—­ì „íŒŒ(backpropagation)í•œë‹¤.
6. ë³€í™”ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•œë‹¤.

   * ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜(weight) = ê°€ì¤‘ì¹˜(weight) - í•™ìŠµë¥ (learning rate) * ë³€í™”ë„(gradient)

   - learning rateëŠ” ë‚´ê°€ ì¡°ì ˆ

---

### ì‹ ê²½ë§ êµ¬ì¡° ì˜ˆì‹œ
![alt text](image.png)


```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5) # ì±„ë„ì´ 1ê°œì¸ ì…ë ¥(ex. í‘ë°±ì´ë¯¸ì§€)ì„ ë°›ì•„ 6ê°œì˜ 5X5 í•„í„°ë¥¼ ì ìš©í•˜ì—¬ 6ê°œì˜ feature mapì„ ì¶œë ¥í•˜ëŠ” layer -> ë‹¤ìŒ layerê°€ ì´ 6ê°œ feature ë°›ì•„ì•¼í•¨
        # 1ì±„ë„ ì´ë¯¸ì§€ -> 6ì±„ë„
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16*5*5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
```
- output 
```
Net(
  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
```

### feature mapì´ë€?(Activation map)
í”¼ì²˜ ë§µ(Feature Map)ì€ **í•„í„°(Filter)ê°€ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ í›‘ê³  ì§€ë‚˜ê°€ë©´ì„œ ì°¾ì•„ë‚¸ íŠ¹ì • íŠ¹ì§•(Feature)ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ê²°ê³¼ë¬¼**ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤. í™œì„±í™” ë§µ(Activation Map)ì´ë¼ê³ ë„ ë¶€ë¦…ë‹ˆë‹¤.

ì¡°ê¸ˆ ë” ì‰½ê²Œ ë¹„ìœ í•´ ë³´ê² ìŠµë‹ˆë‹¤.
![alt text](image-2.png)

-----

### ë‹ë³´ê¸° ë¹„ìœ  ğŸ”

ì—¬ê¸°ì— ì—¬ëŸ¬ ê°€ì§€ ëª¨ì–‘ì´ ê·¸ë ¤ì§„ ê·¸ë¦¼(ì…ë ¥ ì´ë¯¸ì§€)ì´ ìˆë‹¤ê³  ìƒìƒí•´ ë³´ì„¸ìš”.

1.  **í•„í„°(Filter) = íŠ¹ë³„í•œ ë‹ë³´ê¸°**:

      * 'ì„¸ë¡œì„ ë§Œ ë³´ì—¬ì£¼ëŠ” ë‹ë³´ê¸°'ê°€ ìˆë‹¤ê³  í•´ë´…ì‹œë‹¤. ì´ ë‹ë³´ê¸°ê°€ ë°”ë¡œ **í•„í„°**ì…ë‹ˆë‹¤.
      * ë‹¤ë¥¸ ë‹ë³´ê¸°ëŠ” 'ê°€ë¡œì„ ë§Œ', ë˜ ë‹¤ë¥¸ ë‹ë³´ê¸°ëŠ” 'ë™ê·¸ë¼ë¯¸ë§Œ' ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. CNNì—ì„œëŠ” ì´ëŸ° íŠ¹ì§•ì„ ê°ì§€í•˜ëŠ” í•„í„°ê°€ ì—¬ëŸ¬ ê°œ ìˆìŠµë‹ˆë‹¤. 

2.  **í”¼ì²˜ ë§µ(Feature Map) = ë‹ë³´ê¸°ë¡œ ë³¸ ê²°ê³¼**:

      * 'ì„¸ë¡œì„  ë‹ë³´ê¸°'(í•„í„°)ë¥¼ ë“¤ê³  ì›ë³¸ ê·¸ë¦¼ ìœ„ë¥¼ ì­‰ í›‘ì–´ë´…ë‹ˆë‹¤.
      * ê·¸ë¦¼ì—ì„œ **ì„¸ë¡œì„ ì´ ìˆëŠ” ë¶€ë¶„ì€ ë°ê²Œ ë¹›ë‚˜ê³ , ì—†ëŠ” ë¶€ë¶„ì€ ì–´ë‘¡ê²Œ ë³´ì´ëŠ” ìƒˆë¡œìš´ ê·¸ë¦¼**ì´ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.
      * ë°”ë¡œ ì´ 'ë‹ë³´ê¸°ë¡œ ë³¸ ê²°ê³¼ë¬¼'ì´ **í”¼ì²˜ ë§µ**ì…ë‹ˆë‹¤. ì¦‰, "ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ì„¸ë¡œì„ ì´ë¼ëŠ” íŠ¹ì§•(Feature)ì´ ì–´ë””ì— ê°•í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ì§€(Map)"ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§€ë„ì¸ ì…ˆì…ë‹ˆë‹¤. -> ì•½ê°„ ì˜ìƒì²˜ë¦¬ í•„í„° ê·¸ëŸ°ëŠë‚Œ..?

-----

### `nn.Conv2d(1, 6, 5)` ì˜ˆì‹œì™€ ì—°ê²°

ì´ì „ ì§ˆë¬¸ì—ì„œ `out_channels=6`ì€ 6ê°œì˜ í•„í„°ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸ë¼ê³  ì„¤ëª…ë“œë ¸ìŠµë‹ˆë‹¤.

  * ì´ 6ê°œì˜ í•„í„°ëŠ” ê°ê° ë‹¤ë¥¸ íŠ¹ì§•ì„ ì°¾ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤.

      * **í•„í„° 1**: ìˆ˜ì§ì„ ì„ ì°¾ëŠ” ë‹ë³´ê¸°
      * **í•„í„° 2**: ìˆ˜í‰ì„ ì„ ì°¾ëŠ” ë‹ë³´ê¸°
      * **í•„í„° 3**: ë‘¥ê·¼ ëª¨ì„œë¦¬ë¥¼ ì°¾ëŠ” ë‹ë³´ê¸°
      * **í•„í„° 4**: íŠ¹ì • ì§ˆê°ì„ ì°¾ëŠ” ë‹ë³´ê¸°
      * ... ë“±ë“±

  * ë”°ë¼ì„œ ì…ë ¥ ì´ë¯¸ì§€ í•˜ë‚˜ê°€ ì´ ë ˆì´ì–´ë¥¼ í†µê³¼í•˜ë©´, **ê° í•„í„°ë§ˆë‹¤ í•˜ë‚˜ì”©, ì´ 6ê°œì˜ í”¼ì²˜ ë§µ**ì´ ì¶œë ¥ë©ë‹ˆë‹¤.

      * **í”¼ì²˜ ë§µ 1**: "ìˆ˜ì§ì„ ì´ ì–´ë””ì— ìˆëŠ”ì§€"ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€ë„
      * **í”¼ì²˜ ë§µ 2**: "ìˆ˜í‰ì„ ì´ ì–´ë””ì— ìˆëŠ”ì§€"ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€ë„
      * **í”¼ì²˜ ë§µ 3**: "ë‘¥ê·¼ ëª¨ì„œë¦¬ê°€ ì–´ë””ì— ìˆëŠ”ì§€"ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€ë„
      * ... ì´ë ‡ê²Œ 6ê°œê°€ ìƒì„±ë©ë‹ˆë‹¤.

### ìš”ì•½

í”¼ì²˜ ë§µ(Feature Map)ì´ë€?

> **í•˜ë‚˜ì˜ í•„í„°(Filter)ê°€ ì´ë¯¸ì§€ ì „ì²´ë¥¼ ìŠ¤ìº”í•˜ë©°, ìê¸°ê°€ ë§¡ì€ íŠ¹ì§•ì´ ì´ë¯¸ì§€ì˜ ì–´ëŠ ë¶€ë¶„ì— ì¡´ì¬í•˜ëŠ”ì§€ë¥¼ í‘œì‹œí•œ ê²°ê³¼ë¬¼**ì…ë‹ˆë‹¤.

ì‹ ê²½ë§ì€ ì´ë ‡ê²Œ ìƒì„±ëœ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ í”¼ì²˜ ë§µ(ìˆ˜ì§ì„ , ê³¡ì„ , ì§ˆê° ë“±)ì„ ì¢…í•©ì ìœ¼ë¡œ ë³´ê³  "ì•„, ì´ ì´ë¯¸ì§€ì—ëŠ” ëˆˆê³¼ ì½”, ë¾°ì¡±í•œ ê·€ ëª¨ì–‘ì˜ íŠ¹ì§•ë“¤ì´ ìˆìœ¼ë‹ˆ ê³ ì–‘ì´ì¼ í™•ë¥ ì´ ë†’ê² êµ°\!" í•˜ê³  íŒë‹¨í•˜ê²Œ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

---

###  ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ

```python
net = Net()
input = torch.randn(1, 1, 32, 32)
output = net(input)
```

ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ëŠ” `net.parameters()`ë¡œ ì ‘ê·¼í•œë‹¤.

---

### ì†ì‹¤ í•¨ìˆ˜ (Loss Function)

```python
criterion = nn.MSELoss()
loss = criterion(output, target)
```

`.grad_fn`ìœ¼ë¡œ ì—°ì‚° ê·¸ë˜í”„ë¥¼ ì¶”ì í•  ìˆ˜ ìˆë‹¤.
`loss.backward()`ë¥¼ í˜¸ì¶œí•˜ë©´ ì—­ì „íŒŒê°€ ìˆ˜í–‰ë˜ë©° `.grad`ì— ë³€í™”ë„ê°€ ëˆ„ì ëœë‹¤.

---

### ê°€ì¤‘ì¹˜ ê°±ì‹  (Gradient Descent)

#### ìˆ˜ë™ ê°±ì‹ :

```python
learning_rate = 0.01
for param in net.parameters():
    param.data.sub_(learning_rate * param.grad.data) # Gradient Descent ì§ì ‘
```

#### Optimizer ì‚¬ìš©:

```python
import torch.optim as optim
optimizer = optim.SGD(net.parameters(), lr=0.01)

optimizer.zero_grad()
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()
```

---

### ì •ë¦¬

| ê°œë…                  | ì„¤ëª…                                       |
| ------------------- | ---------------------------------------- |
| `torch.Tensor`      | ìë™ ë¯¸ë¶„ì„ ì§€ì›í•˜ëŠ” ë‹¤ì°¨ì› ë°°ì—´ì´ë‹¤.                    |
| `nn.Module`         | ì‹ ê²½ë§ ê³„ì¸µì˜ ê¸°ë³¸ ë‹¨ìœ„ì´ë©°, íŒŒë¼ë¯¸í„° ê´€ë¦¬ ë° GPU ì „ì†¡ì„ ì§€ì›í•œë‹¤. |
| `nn.Parameter`      | `Module`ì— ë“±ë¡ë˜ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ì´ë‹¤.            |
| `autograd.Function` | ìˆœë°©í–¥ ë° ì—­ë°©í–¥ ì—°ì‚°ì„ ì •ì˜í•˜ë©°, ì—°ì‚° ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•œë‹¤.        |

