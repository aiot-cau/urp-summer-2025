# Pytorch ë°ì´í„° ì²˜ë¦¬
- Dataset: ë°ì´í„°ì…‹ ì „ì²´ë¥¼ í‘œí˜„í•˜ë©° __len__, __getitem__ êµ¬í˜„ í•„ìš” 
- ë§¤ë²ˆ ì •ì˜í•´ì¤˜ì•¼í•˜ë‚˜? => ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì´ë©´ YES
- DataLoader: Datasetì„ ìˆœíšŒ ê°€ëŠ¥í•œ(minibatch ë‹¨ìœ„) ê°ì²´ë¡œ ê°ì‹¸ì¤Œ


# ë°ì´í„° ë¡œë”©
```python
training_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor()
)

test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor()
)
```
- train = True, False ì •ë„ì˜ ì°¨ì´ë§Œ ìˆìŒ

# ì‚¬ìš©ì ì •ì˜ `Dataset` í´ë˜ìŠ¤ ë§Œë“¤ê¸°
```python
from torch.utils.data import Dataset
import os, pandas as pd
from torchvision.io import read_image

# ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ í´ë˜ìŠ¤
class CustomImageDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
        """
        ì´ˆê¸°í™” í•¨ìˆ˜
        - annotations_file: ì´ë¯¸ì§€ íŒŒì¼ëª…ê³¼ ë¼ë²¨ì´ ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ
        - img_dir: ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        - transform: ì´ë¯¸ì§€ì— ì ìš©í•  transform í•¨ìˆ˜ (ì˜ˆ: ToTensor(), Normalize ë“±)
        - target_transform: ë¼ë²¨ì— ì ìš©í•  transform í•¨ìˆ˜
        """
        # CSV íŒŒì¼ì„ ì½ì–´ DataFrameìœ¼ë¡œ ì €ì¥ (ì»¬ëŸ¼ëª… ì§€ì •)
        self.img_labels = pd.read_csv(annotations_file, names=["file_name", "label"])
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        """
        ì „ì²´ ìƒ˜í”Œ ìˆ˜ë¥¼ ë°˜í™˜
        """
        return len(self.img_labels)

    def __getitem__(self, idx):
        """
        ì£¼ì–´ì§„ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œ(ì´ë¯¸ì§€, ë¼ë²¨)ì„ ë°˜í™˜
        - idx: ìƒ˜í”Œ ì¸ë±ìŠ¤
        """
        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        
        # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ì½ì–´ì˜¤ê¸°
        image = read_image(img_path)
        
        # ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
        label = self.img_labels.iloc[idx, 1]
        
        # ì´ë¯¸ì§€ì— transform ì ìš© (ì„ íƒì )
        if self.transform:
            image = self.transform(image)
        
        # ë¼ë²¨ì— transform ì ìš© (ì„ íƒì )
        if self.target_transform:
            label = self.target_transform(label)
        
        # ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
        return {"image": image, "label": label}

```
- `read_image` => ì´ë¯¸ì§€ë¥¼ tensorë¡œ ë³€í™˜í•´ì„œ ê°€ì ¸ì˜´
- `img_labels` => csv ë°ì´í„°ì—ì„œ ì •ë‹µ ê°’ë§Œ ì½ì–´ì˜´(ì¸ë±ìŠ¤ 1ì´ labelì´ë¼ì €ë ‡ê²Œ ì“´ ê²ƒ) - idx == í–‰, 1 == ì—´

# ê·¼ë° ìœ„ì—ì„œ ì •ë‹µê°’(label)ì— ì™œ transform??
ì •ë‹µ(label)ì— `transform`ì„ ê±°ëŠ” ì´ìœ ëŠ” **ì •ë‹µê°’ì´ ëª¨ë¸ì´ ë°”ë¡œ ì‚¬ìš©í•˜ê¸° ì–´ë ¤ìš´ í˜•íƒœì¼ ìˆ˜ ìˆê¸° ë•Œë¬¸**ì´ì—ìš”. ì•„ë˜ì— ì£¼ìš” ì´ìœ ë¥¼ ì •ë¦¬í•´ì¤„ê²Œìš”.

---

### âœ… ì™œ ì •ë‹µ(label)ì— `target_transform`ì„ ì ìš©í•˜ë‚˜?

#### 1. **í´ë˜ìŠ¤ ì´ë¦„ â†’ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•  ë•Œ**

ì˜ˆë¥¼ ë“¤ì–´, ì •ë‹µì´ `"cat"`, `"dog"`ì²˜ëŸ¼ ë¬¸ìì—´ì¸ ê²½ìš°, ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìˆ«ìë¡œ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.

```python
target_transform = lambda x: {"cat": 0, "dog": 1}[x]
```

#### 2. **ì •ë‹µì„ One-hot ë²¡í„°ë¡œ ë³€í™˜í•  ë•Œ**

ëª¨ë¸ ì¶œë ¥ì´ softmaxì´ê³  one-hot ë ˆì´ë¸”ì´ í•„ìš”í•œ ê²½ìš°:

```python
target_transform = lambda x: F.one_hot(torch.tensor(x), num_classes=10)
```

#### 3. **ì •ë‹µê°’ì˜ dtype ë³€í™˜ì´ í•„ìš”í•  ë•Œ**

ì˜ˆë¥¼ ë“¤ì–´ `float`ë¡œ ë°”ê¿”ì•¼ í•˜ëŠ” íšŒê·€ ë¬¸ì œë¼ë©´:

```python
target_transform = lambda x: torch.tensor(x, dtype=torch.float)
```

---

### ğŸ“Œ ì •ë¦¬

* `transform`: ì…ë ¥ ë°ì´í„°(X)ì— ì ìš© â†’ ì˜ˆ: `ToTensor()`, `Normalize()`
* `target_transform`: ì •ë‹µ(y)ì— ì ìš© â†’ ì˜ˆ: ì¸ë±ì‹±, one-hot, í˜•ë³€í™˜ ë“±

> ì¦‰, ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì¢‹ì€ **ì •ë‹µ í˜•íƒœë¡œ ê°€ê³µ**í•˜ëŠ” ê²Œ `target_transform`ì˜ ëª©ì ì…ë‹ˆë‹¤.

---

ì˜ˆë¥¼ ë“¤ì–´, ì •ë‹µì´ `"ankle_boot"`ì²˜ëŸ¼ ë¬¸ìì—´ì¼ ê²½ìš° ìˆ«ìë¡œ ë°”ê¾¸ëŠ” transformì„ ì“¸ ìˆ˜ ìˆê² ì£ :

```python
label_map = {"tshirt": 0, "trouser": 1, ..., "ankle_boot": 9}
target_transform = lambda y: label_map[y]
```

í•„ìš” ì—†ëŠ” ê²½ìš°ëŠ” `None`ìœ¼ë¡œ ë‘ë©´ ë©ë‹ˆë‹¤.


# ê·¸ëŸ¼ ì´ê±´ ì´ë¯¸ì§€ì— ì“°ì´ëŠ” transformì´ë‘ ë‹¤ë¥¸ê±°ë„¤ normalization ì´ëŸ°ê±´ ì•„ë‹ˆë‹ˆê¹Œ

### âœ… í•µì‹¬ ì •ë¦¬

| í•­ëª©                 | ëª©ì                               | ì˜ˆì‹œ transform                                       | ì ìš© ëŒ€ìƒ   |
| ------------------ | ------------------------------- | -------------------------------------------------- | ------- |
| `transform`        | **ì´ë¯¸ì§€ ì „ì²˜ë¦¬** (ëª¨ë¸ ì…ë ¥ì— ì í•©í•˜ê²Œ ë§Œë“¦)    | `ToTensor()`, `Normalize(mean, std)`, `Resize()` ë“± | `image` |
| `target_transform` | **ì •ë‹µ(ë¼ë²¨) ì „ì²˜ë¦¬** (ëª¨ë¸ í•™ìŠµì— ì í•©í•œ í˜•íƒœë¡œ) | `lambda x: one_hot(x)`, `int(x)`, `label_map[x]` ë“± | `label` |

---

### ğŸ“Œ ì˜ˆì‹œ ë¹„êµ

#### ì´ë¯¸ì§€ìš© transform (ì…ë ¥ X)

```python
transform = transforms.Compose([
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])
```

#### ì •ë‹µìš© target\_transform (ì •ë‹µ y)

```python
target_transform = lambda y: torch.tensor(y, dtype=torch.long)
```

---

### â— ë‘˜ì€ ëª©ì ê³¼ ì ìš© ëŒ€ìƒì´ ì™„ì „íˆ ë‹¤ë¦…ë‹ˆë‹¤

* `transform`ì€ **ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë°”ê¾¸ê³  ì •ê·œí™”(Normalization)** í•´ì„œ **ëª¨ë¸ ì…ë ¥**ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì¢‹ê²Œ ë§Œë“œëŠ” ê³¼ì •ì´ê³ ,
* `target_transform`ì€ **ì •ë‹µ ë ˆì´ë¸”ì´ í…ìŠ¤íŠ¸ì´ê±°ë‚˜, í¬ë§·ì´ ë§ì§€ ì•Šì„ ë•Œ ê°€ê³µí•˜ëŠ” ë³´ì¡° ìˆ˜ë‹¨**ì´ì—ìš”.

---

í•„ìš” ì—†ìœ¼ë©´ `None`ìœ¼ë¡œ ì„¤ì •í•´ë„ ë˜ê³ , ë‘˜ ë‹¤ ì“°ëŠ” ê²½ìš°ë„ ë§ìŒ

```python
CustomImageDataset(..., transform=transform, target_transform=target_transform)
```

ì´ë ‡ê²Œ ì“°ë©´ ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë‘˜ ë‹¤ ì ì ˆíˆ ì „ì²˜ë¦¬ë˜ì–´ ëª¨ë¸ì— ì…ë ¥ë  ìˆ˜ ìˆì£ .

# DataLoader

 
### âœ… ì—­í• 

`DataLoader`ëŠ” `Dataset`ìœ¼ë¡œë¶€í„° ë°ì´í„°ë¥¼ **íš¨ìœ¨ì ìœ¼ë¡œ êº¼ë‚´ì£¼ëŠ” ë„êµ¬**ì…ë‹ˆë‹¤.

### âœ… ì£¼ìš” ê¸°ëŠ¥

* ë°ì´í„°ë¥¼ **ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„(batch)** ë¡œ ë¶ˆëŸ¬ì˜´
* **ì—í­ë§ˆë‹¤ ì„ê¸°(shuffle)** ì§€ì›
* **ë³‘ë ¬ ì²˜ë¦¬(multiprocessing)** ë¡œ ë¡œë”© ì†ë„ í–¥ìƒ
* ë°˜ë³µ ê°€ëŠ¥í•œ ê°ì²´(iterable)ë¡œ ì‚¬ìš© ê°€ëŠ¥ â†’ `for batch in loader:` í˜•íƒœ

---

### ğŸ§ª ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from torch.utils.data import DataLoader

train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)
```

* `batch_size=64`: í•œ ë²ˆì— 64ê°œ ìƒ˜í”Œ ë°˜í™˜
* `shuffle=True`: ë§¤ epochë§ˆë‹¤ ë°ì´í„° ìˆœì„œ ì„ìŒ

---

### ğŸ” ìˆœíšŒ ì˜ˆì‹œ (í•™ìŠµ ë£¨í”„ìš©)

```python
for batch in train_dataloader:
    images, labels = batch
    # ëª¨ë¸ì— ì…ë ¥: model(images)
```

ë˜ëŠ” í•œ ë²ˆë§Œ êº¼ë‚´ë³¼ ë•:

```python
images, labels = next(iter(train_dataloader))
print(images.shape)  # torch.Size([64, 1, 28, 28])
print(labels.shape)  # torch.Size([64])
```

---

### ğŸ‘€ ì‹œê°í™” ì˜ˆì‹œ

```python
img = images[0].squeeze()
label = labels[0]
plt.imshow(img, cmap="gray")
plt.title(f"Label: {label}")
plt.show()
```

---

### ğŸ“ ìš”ì•½

| ê¸°ëŠ¥            | ì„¤ëª…                       |
| ------------- | ------------------------ |
| `batch_size`  | í•œ ë²ˆì— ë°˜í™˜í•  ë°ì´í„° ìˆ˜           |
| `shuffle`     | ì—í­ë§ˆë‹¤ ìˆœì„œ ì„ê¸°               |
| `num_workers` | ë°ì´í„° ë¡œë”©ì— ì‚¬ìš©í•  subprocess ìˆ˜ |
| `drop_last`   | ë§ˆì§€ë§‰ ë‚¨ì€ ë¶ˆì™„ì „ ë°°ì¹˜ ë²„ë¦´ì§€ ì—¬ë¶€     |

---